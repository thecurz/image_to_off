{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm  \n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Activation\n",
    "from keras.layers import Embedding, Lambda, Concatenate, Add\n",
    "from keras.layers import Conv3DTranspose, Conv3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "import keras.backend as K\n",
    "from keras.layers import Conv2D, Conv2DTranspose, Reshape\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Activation\n",
    "from keras.layers import Embedding, Lambda, Concatenate, Add\n",
    "from keras.layers import GlobalAvgPool3D, Multiply\n",
    "from keras.layers import Conv3DTranspose, Conv3D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "import keras.backend as K\n",
    "\n",
    "dataset_path = \"ModelNet40\"\n",
    "images_path = \"images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_layer(inp, f, act='relu', bn=True):\n",
    "    initializer = act if act is not None else ''\n",
    "    initializer = 'he_uniform' if initializer.find('relu') != -1 else 'glorot_uniform'\n",
    "    out = Dense(f, use_bias=False, kernel_initializer=initializer)(inp)\n",
    "    if bn: out = BatchNormalization()(out)\n",
    "    \n",
    "    if act == 'lrelu':\n",
    "        out = LeakyReLU(alpha=0.2)(out)\n",
    "    elif act is not None:\n",
    "        out = Activation(act)(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def conv_layer(inp, f, k=4, s=2, p='same', act='relu', bn=True, transpose=False,\n",
    "               se=False, se_ratio=16):\n",
    "    initializer = act if act is not None else ''\n",
    "    initializer = 'he_uniform' if initializer.find('relu') != -1 else 'glorot_uniform'\n",
    "    fun = Conv3DTranspose if transpose else Conv3D\n",
    "    out = fun(f, k, strides=s, padding=p, use_bias=False, kernel_initializer=initializer)(inp)\n",
    "    if bn: out = BatchNormalization()(out)\n",
    "    \n",
    "    if act == 'lrelu':\n",
    "        out = LeakyReLU(alpha=0.2)(out)\n",
    "    elif act is not None:\n",
    "        out = Activation(act)(out)\n",
    "\n",
    "    # squeeze and excite\n",
    "    if se:\n",
    "        out_se = GlobalAvgPool3D()(out)\n",
    "        r = f // se_ratio if (f // se_ratio) > 0 else 1\n",
    "        out_se = Reshape((1, 1, f))(out_se)\n",
    "        out_se = Dense(r, use_bias=False, kernel_initializer='he_uniform',\n",
    "                       activation='relu')(out_se)\n",
    "        out_se = Dense(f, use_bias=False, activation='sigmoid')(out_se)\n",
    "        out = Multiply()([out, out_se])\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _generator_v_3d(dict_size):\n",
    "    # inputs\n",
    "    labels = Input(shape=(1,))\n",
    "    image_inp = Input(shape=(128, 128, 1))\n",
    "    image = Lambda(lambda x: K.expand_dims(x))(image_inp)\n",
    "    \n",
    "    # label embedding\n",
    "    embs = Embedding(dict_size, 64, input_length=1)(labels)\n",
    "    embs = Flatten()(embs)\n",
    "    embs = dense_layer(embs, 1024)\n",
    "    \n",
    "    # conv layers for image processing\n",
    "    image_conv1 = Conv2D(32, kernel_size=5, strides=1, padding=\"same\", activation=\"relu\")(image)\n",
    "    image_conv2 = Conv2D(32, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(image_conv1)\n",
    "    image_conv3 = Conv2D(64, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(image_conv2)\n",
    "    image_conv4 = Conv2D(128, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(image_conv3)\n",
    "    image_conv5 = Conv2D(256, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(image_conv4)\n",
    "    \n",
    "    image_flatten = Flatten()(image_conv5)\n",
    "    \n",
    "    # Merge label embedding and processed image\n",
    "    mix = Concatenate()([image_flatten, embs])\n",
    "    mix = dense_layer(mix, 1024)\n",
    "    mix = dense_layer(mix, 2*2*2*256)\n",
    "    mix = Lambda(lambda x: K.reshape(x, (-1, 2, 2, 2, 256)))(mix)\n",
    "\n",
    "    # Transpose convolution layers\n",
    "    out = Conv3DTranspose(256, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\", activation=\"relu\")(mix)\n",
    "    out = Conv3DTranspose(128, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\", activation=\"relu\")(out)\n",
    "    out = Conv3DTranspose(64, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\", activation=\"relu\")(out)\n",
    "    out = Conv3DTranspose(32, kernel_size=(3, 3, 3), strides=(2, 2, 2), padding=\"same\", activation=\"relu\")(out)\n",
    "    \n",
    "    # Output layer\n",
    "    out = Conv3D(1, kernel_size=(3, 3, 3), padding=\"same\", activation=\"tanh\")(out)\n",
    "    \n",
    "    return Model((image_inp, labels), out)\n",
    "# Discriminator models:\n",
    "\n",
    "def _discriminator(dict_size, se=False):\n",
    "    # inputs\n",
    "    labels = Input(shape=(1,))\n",
    "    voxels_inp = Input(shape=(128,128,1))\n",
    "    voxels = Lambda(lambda x: K.expand_dims(x))(voxels_inp)\n",
    "    \n",
    "    # label embedding\n",
    "    embs = Embedding(dict_size, 64, input_length=1)(labels)\n",
    "    embs = Flatten()(embs)\n",
    "    embs = dense_layer(embs, 1024, act='lrelu', bn=False)\n",
    "    \n",
    "    # conv layers\n",
    "    out = conv_layer(voxels, 32, 5, 1, act='lrelu', bn=False, se=se)\n",
    "    out = conv_layer(out, 32, act='lrelu', bn=False, se=se)\n",
    "    out = conv_layer(out, 64, act='lrelu', bn=False, se=se)\n",
    "    out = conv_layer(out, 128, act='lrelu', bn=False, se=se)\n",
    "    out = conv_layer(out, 256, act='lrelu', bn=False, se=se)\n",
    "    out = Flatten()(out)\n",
    "    out = dense_layer(out, 1024, act='lrelu', bn=False)\n",
    "    out = Concatenate()([out, embs])\n",
    "    out = dense_layer(out, 1024, act='lrelu', bn=False)\n",
    "    out = dense_layer(out, 512, act='lrelu', bn=False)\n",
    "    out = dense_layer(out, 1, act=None, bn=False)\n",
    "    \n",
    "    return Model((voxels_inp, labels), out)\n",
    "\n",
    "def make_discriminator(dict_size, model_type):\n",
    "    model = {\n",
    "        'voxels-v': _discriminator(dict_size),\n",
    "        'voxels-u': _discriminator(dict_size),\n",
    "        'voxels-use': _discriminator(dict_size, se=True)\n",
    "    }\n",
    "    \n",
    "    return model[model_type]\n",
    "\n",
    "def make_generator(dict_size, model_type):\n",
    "    model = {\n",
    "        'voxels-v': _generator_v(dict_size),\n",
    "        'voxels-u': _generator_u(dict_size),\n",
    "        'voxels-use': _generator_u(dict_size, se=True)\n",
    "    }\n",
    "    \n",
    "    return model[model_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_files(folder_path):\n",
    "    model_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".off\"):  # Adjust the file extension as needed\n",
    "                model_files.append(os.path.join(root, file))\n",
    "    return model_files\n",
    "\n",
    "def load_model_data(file_path):\n",
    "    # Implement your code to load 3D model data from the file\n",
    "    # You might use the readOff function or any other method\n",
    "    # Return the loaded model data\n",
    "    pass\n",
    "\n",
    "def generate_dataset(data_folder):\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "\n",
    "    # Iterate over the object class folders\n",
    "    for class_folder in tqdm(os.listdir(data_folder)):\n",
    "        if class_folder.lower() == 'bathtub':  # Skip the \"bathtub\" folder\n",
    "            continue\n",
    "\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "\n",
    "        # Skip non-directory items\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        # Load model files for the current class\n",
    "        model_files = load_model_files(class_path)\n",
    "\n",
    "        # Split the model files into train and test sets\n",
    "        split_index = int(len(model_files) * 0.8)  # Adjust the split ratio as needed\n",
    "        train_files = model_files[:split_index]\n",
    "        test_files = model_files[split_index:]\n",
    "\n",
    "        # Load train set\n",
    "        for file in train_files:\n",
    "            model_data = load_model_data(file)\n",
    "            X_train.append(model_data)\n",
    "\n",
    "        # Load test set\n",
    "        for file in test_files:\n",
    "            model_data = load_model_data(file)\n",
    "            X_test.append(model_data)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readOff(filename):\n",
    "    f = open(filename)\n",
    "    f.readline()\n",
    "    nvertices, nfaces, nedges = map(int, f.readline().split())\n",
    "    vertices = []\n",
    "    for _ in range(nvertices):\n",
    "        vertices.append(list(map(float, f.readline().strip().split())))\n",
    "    vertices = np.array(vertices)\n",
    "\n",
    "    triangles = []\n",
    "    for _ in range(nfaces):\n",
    "        face = list(map(int, f.readline().strip().split()))\n",
    "        ntriangles, verts = face[0] - 3 + 1, face[1:]\n",
    "        for n in range(ntriangles):\n",
    "            triangles.append([verts[0], verts[1 + n], verts[2 + n]])\n",
    "    triangles = np.array(triangles)\n",
    "\n",
    "    return vertices, triangles\n",
    "\n",
    "def save_png(off_filename, png_filename):\n",
    "    vertices, faces = readOff(off_filename)\n",
    "\n",
    "    x, y, z = vertices.T\n",
    "    I, J, K = faces.T\n",
    "\n",
    "    mesh = go.Mesh3d(\n",
    "        x=-x,\n",
    "        y=y,\n",
    "        z=z,\n",
    "        i=I,\n",
    "        j=J,\n",
    "        k=K,\n",
    "        name='',\n",
    "        showscale=False,\n",
    "        color='brown'\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=mesh)\n",
    "    fig.update_layout(\n",
    "        scene=dict(\n",
    "            xaxis=dict(visible=False),\n",
    "            yaxis=dict(visible=False),\n",
    "            zaxis=dict(visible=False)\n",
    "        )\n",
    "    )\n",
    "    fig.write_image(png_filename)\n",
    "    # print(f\"Image saved as {png_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_data(data_folder, output_folder):\n",
    "    for class_folder in os.listdir(data_folder):\n",
    "        if class_folder.lower() == 'bathtub':  # Skip the \"bathtub\" folder\n",
    "            continue\n",
    "\n",
    "        class_path = os.path.join(data_folder, class_folder)\n",
    "\n",
    "        # Skip non-directory items\n",
    "        if not os.path.isdir(class_path):\n",
    "            continue\n",
    "\n",
    "        output_class_folder = os.path.join(output_folder, class_folder)\n",
    "        os.makedirs(output_class_folder, exist_ok=True)\n",
    "\n",
    "        for split_folder in ['train', 'test']:\n",
    "            split_path = os.path.join(class_path, split_folder)\n",
    "\n",
    "            for model_file in os.listdir(split_path):\n",
    "                if model_file.endswith(\".off\"):  # Adjust the file extension as needed\n",
    "                    off_file_path = os.path.join(split_path, model_file)\n",
    "                    png_file_name = f\"{model_file[:-4]}_{split_folder}.png\"\n",
    "                    png_file_path = os.path.join(output_class_folder, png_file_name)\n",
    "\n",
    "                    save_png(off_file_path, png_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:00<00:00, 597.03it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = generate_dataset(dataset_path)\n",
    "#generate_and_save_data(dataset_path, images_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GlobalAvgPool3D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\theca\\Documents\\Python\\ML\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dict_size \u001b[39m=\u001b[39m \u001b[39m40\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m  \n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m discriminator \u001b[39m=\u001b[39m make_discriminator(dict_size, \u001b[39m'\u001b[39;49m\u001b[39mvoxels-use\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m discriminator\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbinary_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mAdam(lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m, beta_1\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m discriminator\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\theca\\Documents\\Python\\ML\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_discriminator\u001b[39m(dict_size, model_type):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     model \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvoxels-v\u001b[39m\u001b[39m'\u001b[39m: _discriminator(dict_size),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvoxels-u\u001b[39m\u001b[39m'\u001b[39m: _discriminator(dict_size),\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvoxels-use\u001b[39m\u001b[39m'\u001b[39m: _discriminator(dict_size, se\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m model[model_type]\n",
      "\u001b[1;32mc:\\Users\\theca\\Documents\\Python\\ML\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m embs \u001b[39m=\u001b[39m dense_layer(embs, \u001b[39m1024\u001b[39m, act\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlrelu\u001b[39m\u001b[39m'\u001b[39m, bn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m \u001b[39m# conv layers\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m out \u001b[39m=\u001b[39m conv_layer(voxels, \u001b[39m32\u001b[39;49m, \u001b[39m5\u001b[39;49m, \u001b[39m1\u001b[39;49m, act\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mlrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, bn\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, se\u001b[39m=\u001b[39;49mse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m out \u001b[39m=\u001b[39m conv_layer(out, \u001b[39m32\u001b[39m, act\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlrelu\u001b[39m\u001b[39m'\u001b[39m, bn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, se\u001b[39m=\u001b[39mse)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m out \u001b[39m=\u001b[39m conv_layer(out, \u001b[39m64\u001b[39m, act\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlrelu\u001b[39m\u001b[39m'\u001b[39m, bn\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, se\u001b[39m=\u001b[39mse)\n",
      "\u001b[1;32mc:\\Users\\theca\\Documents\\Python\\ML\\main.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# squeeze and excite\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mif\u001b[39;00m se:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     out_se \u001b[39m=\u001b[39m GlobalAvgPool3D()(out)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     r \u001b[39m=\u001b[39m f \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m se_ratio \u001b[39mif\u001b[39;00m (f \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m se_ratio) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/theca/Documents/Python/ML/main.ipynb#W5sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m     out_se \u001b[39m=\u001b[39m Reshape((\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, f))(out_se)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GlobalAvgPool3D' is not defined"
     ]
    }
   ],
   "source": [
    "dict_size = 40-1  \n",
    "\n",
    "discriminator = make_discriminator(dict_size, 'voxels-use')\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "generator = _generator_v_3d(dict_size)\n",
    "gan_input = [Input(shape=(128, 128, 1)), Input(shape=(1,))]\n",
    "generated_voxel = generator(gan_input)\n",
    "validity = discriminator([generated_voxel, gan_input[1]])\n",
    "gan = Model(gan_input, validity)\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "epochs = 10000  # Adjust as needed\n",
    "batch_size = 64  # Adjust as needed\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # ---------------------\n",
    "    #  Train Discriminator\n",
    "    # ---------------------\n",
    "\n",
    "    # Select a random batch of images\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    real_images = X_train[idx]\n",
    "\n",
    "    # Generate a batch of new images\n",
    "    labels = np.random.randint(0, dict_size, batch_size).reshape((-1, 1))\n",
    "    generated_images = generator.predict([real_images, labels])\n",
    "\n",
    "    # Train the discriminator\n",
    "    d_loss_real = discriminator.train_on_batch([real_images, labels], np.ones((batch_size, 1)))\n",
    "    d_loss_fake = discriminator.train_on_batch([generated_images, labels], np.zeros((batch_size, 1)))\n",
    "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "    # ---------------------\n",
    "    #  Train Generator\n",
    "    # ---------------------\n",
    "\n",
    "    # Generate a batch of new images\n",
    "    labels = np.random.randint(0, dict_size, batch_size).reshape((-1, 1))\n",
    "    valid_y = np.array([1] * batch_size).reshape((-1, 1))\n",
    "\n",
    "    # Train the generator\n",
    "    g_loss = gan.train_on_batch([real_images, labels], valid_y)\n",
    "\n",
    "    # Print progress\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"{epoch} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = np.random.randint(0, dict_size, batch_size).reshape((-1, 1))\n",
    "generated_images = generator.predict([X_test, test_labels])\n",
    "\n",
    "generator.save('generator_model.h5')\n",
    "discriminator.save('discriminator_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
